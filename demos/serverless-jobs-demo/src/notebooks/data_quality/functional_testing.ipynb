{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Functional Testing Notebook\n",
        "# =============================================================================\n",
        "# This notebook demonstrates:\n",
        "# - Custom library usage (Faker, html2text)\n",
        "# - Job parameter configuration\n",
        "# - Spark configuration settings\n",
        "# - Data generation and validation\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import argparse\n",
        "\n",
        "# Get Spark session\n",
        "spark = SparkSession.getActiveSession() or SparkSession.builder.getOrCreate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FUNCTIONAL TESTING - Library & Configuration Demonstration\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Import Job Parameters and Environment Variables\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Get catalog_name from Databricks widgets (job parameter)\n",
        "try:\n",
        "    from pyspark.dbutils import DBUtils\n",
        "    dbutils = DBUtils(spark)\n",
        "    catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
        "except Exception:\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--catalog_name\", type=str, required=True)\n",
        "    args, _ = parser.parse_known_args()\n",
        "    catalog_name = args.catalog_name\n",
        "\n",
        "# Get database_name and location from cluster environment variables\n",
        "database_name = os.environ.get(\"DATABASE_NAME\", \"synthea\")\n",
        "location = os.environ.get(\"LOCATION\", \"/Volumes/maggiedatabricksterraform_dbw/synthea/landing\")\n",
        "\n",
        "print(\"\\nJob Configuration:\")\n",
        "print(f\"  Catalog Name (parameter):     {catalog_name}\")\n",
        "print(f\"  Database Name (env var):      {database_name}\")\n",
        "print(f\"  Location (env var):           {location}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cell 3: Display Spark Configuration (Set at Cluster Level)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nSpark Configuration (configured at cluster level):\")\n",
        "\n",
        "# Display key configurations that are set in the cluster config\n",
        "configs_to_display = [\n",
        "    (\"Delta Preview Enabled\", \"spark.databricks.delta.preview.enabled\"),\n",
        "    (\"Initial Catalog\", \"spark.databricks.sql.initial.catalog.name\"),\n",
        "    (\"Data Lineage Enabled\", \"spark.databricks.dataLineage.enabled\"),\n",
        "    (\"Network Timeout\", \"spark.network.timeout\"),\n",
        "    (\"Legacy Time Parser Policy\", \"spark.sql.legacy.timeParserPolicy\"),\n",
        "    (\"Store Assignment Policy\", \"spark.sql.storeAssignmentPolicy\"),\n",
        "    (\"Parquet Int96 Rebase (Read)\", \"spark.sql.parquet.int96RebaseModeInRead\"),\n",
        "    (\"Parquet Int96 Rebase (Write)\", \"spark.sql.parquet.int96RebaseModeInWrite\"),\n",
        "    (\"Off-Heap Memory\", \"spark.memory.offHeap.enabled\")\n",
        "]\n",
        "\n",
        "for label, config_key in configs_to_display:\n",
        "    try:\n",
        "        value = spark.conf.get(config_key)\n",
        "        print(f\"  {label:.<40} {value}\")\n",
        "    except Exception:\n",
        "        print(f\"  {label:.<40} (not set)\")\n",
        "\n",
        "print(\"\\n✓ All Spark configurations are applied at cluster startup\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Demonstrate Faker Library - Generate Sample Data\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nDemonstrating Faker Library from hls_external_libs wheel...\")\n",
        "\n",
        "try:\n",
        "    from faker import Faker\n",
        "    \n",
        "    # Initialize Faker\n",
        "    fake = Faker()\n",
        "    Faker.seed(42)  # Set seed for reproducibility\n",
        "    \n",
        "    print(\"✓ Faker library imported successfully\")\n",
        "    \n",
        "    # Generate sample patient data\n",
        "    sample_data = []\n",
        "    for i in range(10):\n",
        "        sample_data.append({\n",
        "            'patient_id': fake.uuid4(),\n",
        "            'first_name': fake.first_name(),\n",
        "            'last_name': fake.last_name(),\n",
        "            'email': fake.email(),\n",
        "            'phone': fake.phone_number(),\n",
        "            'address': fake.address().replace('\\n', ', '),\n",
        "            'date_of_birth': fake.date_of_birth(minimum_age=18, maximum_age=90),\n",
        "            'ssn': fake.ssn(),\n",
        "            'blood_type': fake.random_element(elements=('A+', 'A-', 'B+', 'B-', 'O+', 'O-', 'AB+', 'AB-'))\n",
        "        })\n",
        "    \n",
        "    # Convert to DataFrame\n",
        "    from pyspark.sql import Row\n",
        "    df_patients = spark.createDataFrame([Row(**d) for d in sample_data])\n",
        "    \n",
        "    print(f\"\\n✓ Generated {df_patients.count()} sample patient records\")\n",
        "    print(\"\\nSample Generated Data:\")\n",
        "    df_patients.show(5, truncate=False)\n",
        "    \n",
        "    # Display schema\n",
        "    print(\"\\nDataFrame Schema:\")\n",
        "    df_patients.printSchema()\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"✗ Faker not available: {e}\")\n",
        "    print(\"  Note: Faker is available in serverless environments with hls_external_libs wheel\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Demonstrate html2text Library - Parse HTML Content\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nDemonstrating html2text Library from requirements.txt...\")\n",
        "\n",
        "try:\n",
        "    import html2text\n",
        "    \n",
        "    print(\"✓ html2text library imported successfully\")\n",
        "    \n",
        "    # Sample HTML content (simulating healthcare documentation)\n",
        "    sample_html = \"\"\"\n",
        "    <html>\n",
        "    <head><title>Patient Care Summary</title></head>\n",
        "    <body>\n",
        "        <h1>Patient Care Summary Report</h1>\n",
        "        <h2>Patient Information</h2>\n",
        "        <p><strong>Name:</strong> John Doe</p>\n",
        "        <p><strong>MRN:</strong> 123456789</p>\n",
        "        <p><strong>Date:</strong> 2024-01-15</p>\n",
        "        \n",
        "        <h2>Diagnosis</h2>\n",
        "        <ul>\n",
        "            <li>Hypertension (I10)</li>\n",
        "            <li>Type 2 Diabetes (E11.9)</li>\n",
        "            <li>Hyperlipidemia (E78.5)</li>\n",
        "        </ul>\n",
        "        \n",
        "        <h2>Medications</h2>\n",
        "        <table>\n",
        "            <tr><th>Drug</th><th>Dosage</th><th>Frequency</th></tr>\n",
        "            <tr><td>Lisinopril</td><td>10mg</td><td>Once daily</td></tr>\n",
        "            <tr><td>Metformin</td><td>500mg</td><td>Twice daily</td></tr>\n",
        "            <tr><td>Atorvastatin</td><td>20mg</td><td>Once daily</td></tr>\n",
        "        </table>\n",
        "        \n",
        "        <h2>Notes</h2>\n",
        "        <p>Patient reports improved <em>blood glucose control</em> and stable blood pressure readings.</p>\n",
        "        <p><a href=\"https://example.com/followup\">Schedule follow-up appointment</a></p>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize html2text converter\n",
        "    h = html2text.HTML2Text()\n",
        "    h.ignore_links = False\n",
        "    h.ignore_images = True\n",
        "    h.ignore_emphasis = False\n",
        "    \n",
        "    # Convert HTML to markdown/text\n",
        "    markdown_text = h.handle(sample_html)\n",
        "    \n",
        "    print(\"\\n--- Original HTML Content ---\")\n",
        "    print(sample_html[:200] + \"...\")\n",
        "    \n",
        "    print(\"\\n--- Converted to Markdown/Text ---\")\n",
        "    print(markdown_text)\n",
        "    \n",
        "    # Demonstrate parsing multiple HTML snippets\n",
        "    html_snippets = [\n",
        "        (\"<p><strong>Alert:</strong> Lab results available</p>\", \"Alert\"),\n",
        "        (\"<h3>Vital Signs</h3><p>BP: 120/80, HR: 72, Temp: 98.6°F</p>\", \"Vitals\"),\n",
        "        (\"<ul><li>Chest X-Ray: Normal</li><li>CBC: Within normal limits</li></ul>\", \"Lab Results\")\n",
        "    ]\n",
        "    \n",
        "    print(\"\\n--- Batch Processing HTML Snippets ---\")\n",
        "    parsed_data = []\n",
        "    for html_snippet, label in html_snippets:\n",
        "        text = h.handle(html_snippet).strip()\n",
        "        parsed_data.append({'label': label, 'html': html_snippet, 'text': text})\n",
        "        print(f\"\\n{label}:\")\n",
        "        print(f\"  HTML: {html_snippet[:50]}...\")\n",
        "        print(f\"  Text: {text[:50]}...\")\n",
        "    \n",
        "    # Convert to DataFrame\n",
        "    df_parsed = spark.createDataFrame(parsed_data)\n",
        "    print(\"\\n✓ Created DataFrame from parsed HTML content\")\n",
        "    df_parsed.show(truncate=False)\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"✗ html2text not available: {e}\")\n",
        "    print(\"  Note: html2text is available in serverless environments via requirements.txt\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Summary and Completion\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FUNCTIONAL TESTING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n✓ Job Configuration:\")\n",
        "print(f\"    - Catalog (parameter): {catalog_name}\")\n",
        "print(f\"    - Database (env var): {database_name}\")\n",
        "print(f\"    - Location (env var): {location}\")\n",
        "print(\"\\n✓ Spark Configurations:\")\n",
        "print(\"    - 13 custom configurations set at cluster level\")\n",
        "print(\"    - Delta preview enabled\")\n",
        "print(\"    - Data lineage enabled\")\n",
        "print(\"    - Legacy compatibility modes configured\")\n",
        "print(\"\\n✓ Custom Libraries Demonstrated:\")\n",
        "print(\"    - Faker: Installed via init script from custom wheel\")\n",
        "print(\"    - html2text: Available from requirements.txt\")\n",
        "print(\"\\n✓ Functional testing completed successfully!\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
